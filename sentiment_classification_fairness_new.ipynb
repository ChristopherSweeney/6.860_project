{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "import re\n",
    "import statsmodels.formula.api\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib nbagg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protected Groups\n",
    "\n",
    "Race,\n",
    "Color,\n",
    "Religion or creed,\n",
    "National origin or ancestry,\n",
    "Sex,\n",
    "Age,\n",
    "Physical or mental disability,\n",
    "Veteran status,\n",
    "Genetic information,\n",
    "Citizenship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identities = ['lesbian', 'gay', 'bisexual', 'transgender', 'trans', 'queer', \n",
    "              'lgbt', 'lgbtq', 'homosexual', 'straight', 'heterosexual', 'male', \n",
    "              'female', 'nonbinary', 'african', 'african american', 'black', 'white', \n",
    "              'european', 'hispanic', 'latino', 'latina', 'latinx', 'mexican', 'canadian', \n",
    "              'american', 'asian', 'indian', 'middle eastern', 'chinese', 'japanese', \n",
    "              'christian', 'muslim', 'jewish', 'buddhist', 'catholic', 'protestant', 'sikh', \n",
    "              'taoist', 'old', 'older', 'young', 'younger', 'teenage', 'millenial', 'middle aged', \n",
    "              'elderly', 'blind', 'deaf', 'paralyzed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nationalities=[\n",
    "'German',\n",
    "#'African_American',\n",
    "'Mexican',\n",
    "'Irish',\n",
    "'English',\n",
    "'American',\n",
    "'Italian',\n",
    "'Polish',\n",
    "'French',\n",
    "'Scottish',\n",
    "#'Puerto_Rican',\n",
    "'Norwegian',\n",
    "'Dutch',\n",
    "'Swedish',\n",
    "'Chinese',\n",
    "'Indian',\n",
    "'Russian',\n",
    "'Filipino'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "religions =[ \n",
    "    'Zionist',\n",
    "    'Catholic',\n",
    "    'Christian',\n",
    "    'Islamic',\n",
    "    'Protestant',\n",
    "    'Taoist',\n",
    "    'Atheist',\n",
    "    'Hindu',\n",
    "    'Buddhist',\n",
    "    'Diasporic',\n",
    "    'Sikh',\n",
    "    'Juche',\n",
    "    'Jewish',\n",
    "    'Bahai',\n",
    "    'Jains',\n",
    "    'Shinto',\n",
    "    'Pagan'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender= [\"male\",\"female\",\"her\",\"him\",\"man\",\"woman\",\"boy\",\"girl\",\"his\",\"hers\",\"mom\",\"dad\"]#perhaps try all terms intraprotected group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_vector(embeddings,text):\n",
    "    tokens = text.split()\n",
    "    words = filter(lambda x: x in embeddings,[x.lower() for x in words])\n",
    "    if len(words)>0:\n",
    "        return np.mean(embeddings[words],axis = 0)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words_to_toxicity(model,embeddings,words):\n",
    "    words = list(filter(lambda x: x in embeddings,[x.lower() for x in words]))\n",
    "    if len(words)>0:\n",
    "        vector = np.mean(embeddings[words],axis = 0)\n",
    "        prob = model.predict_prob(vector)\n",
    "        return prob\n",
    "    else: return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_toxicity(model,embeddings,text):\n",
    "    tokens = text.split()\n",
    "    toxicity = words_to_toxicity(model,embeddings,tokens)\n",
    "    return toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity_toxicity_table(identities,embeddings,model,add=None):\n",
    "    words = []\n",
    "    toxicities = []\n",
    "    for word in sorted(identities):\n",
    "        word = add + word if add else word\n",
    "        word = word.lower()\n",
    "        toxicities.append(text_to_toxicity(model, embeddings,word.lower()))\n",
    "        words.append(word)\n",
    "    return zip(words,toxicities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_lexicon(filename):\n",
    "    lexicon = []\n",
    "    with open(filename) as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            if line and not line.startswith(';'):\n",
    "                lexicon.append(line)\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_test_set(model,targets,sentences,dim=300):\n",
    "    vectors = np.zeros((len(sentences),dim))\n",
    "    labels = np.zeros((len(sentences)))\n",
    "    count=0\n",
    "    for i,sentence in enumerate(sentences):\n",
    "        words = filter(lambda x: x in model,[x.lower() for x in sentence.split()])\n",
    "        if len(words)>0:\n",
    "            vectors[count,:] = np.mean(model[words],axis = 0)\n",
    "            labels[count] = targets[i] \n",
    "            count+=1\n",
    "    print(count, \" sentences in embeddings, \", len(sentences) - count, \" sentences not in embeddings\")\n",
    "    return train_test_split(vectors, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=5000,val=None,X_tils =[],lamb=.1,reg_coeff=[]):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.val = val\n",
    "        self.X_tils = X_tils\n",
    "        self.lamb = lamb\n",
    "        self.reg_coeff = reg_coeff\n",
    "   \n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    def calculate_fairness_reg_grad(self,theta):\n",
    "        fair_reg_sum = 0\n",
    "        for i,X_til in enumerate(self.X_tils):\n",
    "            l = np.shape(X_til)[0]\n",
    "            z_til = np.dot(X_til, theta)\n",
    "            h_til = self.__sigmoid(z_til)\n",
    "            T = np.sum(h_til)\n",
    "            fair_reg_sum+=self.reg_coeff[i]*(np.sum(X_til.T*h_til*(1-h_til)*(np.log(l*h_til)+1),axis=1))\n",
    "        return fair_reg_sum\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # weights initialization\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        RNSB = []\n",
    "        loss = []\n",
    "        validation_scores = []\n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.__sigmoid(z)\n",
    "            r = self.calculate_fairness_reg_grad(self.theta)\n",
    "            grad_loss = np.dot(X.T, (h - y)) / y.size\n",
    "            #logistic loss + L2 regularization + sum(fair_reg)\n",
    "            if(i % 1000 == 0):\n",
    "                print(np.sum(np.abs(grad_loss)), np.sum(np.abs(2*self.lamb*self.theta)), np.sum(np.abs(r)))\n",
    "            gradient = grad_loss + 2*self.lamb*self.theta+ r\n",
    "            self.theta -= self.lr * gradient\n",
    "            RNSB.append(self.validation_fairness())\n",
    "            loss.append(self.__loss(h, y))\n",
    "            validation_scores.append(self.validation(self.val[0],self.val[1]))\n",
    "            if(i % 1000 == 0):\n",
    "                z = np.dot(X, self.theta)\n",
    "                h = self.__sigmoid(z)\n",
    "                print('loss: ' ,self.__loss(h, y))\n",
    "                if self.val:\n",
    "                    print('validation MAp: ', self.validation(self.val[0],self.val[1]))\n",
    "                if len(self.X_tils)>0:\n",
    "                    print('RNSB: ', self.validation_fairness())\n",
    "        return (RNSB,loss,validation_scores)    \n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        return self.__sigmoid(np.dot(X, self.theta))\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return [1-self.__sigmoid(np.dot(X, self.theta)),self.__sigmoid(np.dot(X, self.theta))]\n",
    "    \n",
    "    def predict(self, X, threshold):\n",
    "        return self.predict_prob(X) >= threshold\n",
    "    \n",
    "    def validation(self,X,Y):\n",
    "        return np.mean(self.predict(X,.5)==Y)\n",
    "    \n",
    "    def validation_fairness(self):\n",
    "        vals = []\n",
    "        for Xtil in self.X_tils:\n",
    "            probs = self.predict_prob(Xtil)\n",
    "            probs = probs/np.sum(probs)\n",
    "            uniform = np.ones(len(probs))*1./len(probs)\n",
    "            vals.append((probs * np.log(probs/uniform)).sum())\n",
    "        return vals\n",
    "    def print_val_fairness(self):\n",
    "        vals = []\n",
    "        for Xtil in self.X_tils:\n",
    "            probs = self.predict_prob(Xtil)\n",
    "            probs = probs/np.sum(probs)\n",
    "            print(probs)\n",
    "            uniform = np.ones(len(probs))*1./len(probs)\n",
    "            vals.append((probs * np.log(probs/uniform)).sum())\n",
    "        print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOVE\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'data/glove.6B/glove.6B.300d.txt'\n",
    "word2vec_output_file = 'data/glove.6B/glove.6B.300d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "embeddings = gensim.models.KeyedVectors.load_word2vec_format(word2vec_output_file,binary=False)\n",
    "\n",
    "#Word2vec\n",
    "# embeddings = gensim.models.KeyedVectors.load_word2vec_format('data/embeddings/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "#universal sentence encoder\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "# module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "# # Import the Universal Sentence Encoder's TF Hub module\n",
    "# embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kaggle\n",
    "\n",
    "#df = pd.read_csv(\"data/kaggle_toxicity/train.csv\")\n",
    "\n",
    "#word sentiment\n",
    "\n",
    "pos_words = load_lexicon(\"data/opinion_lexicon/positive-words.txt\")\n",
    "neg_words = load_lexicon(\"data/opinion_lexicon/negative-words.txt\")\n",
    "\n",
    "#imbd\n",
    "\n",
    "# import numpy\n",
    "# from keras.datasets import imdb\n",
    "# from matplotlib import pyplot\n",
    "# # load the dataset\n",
    "# (X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "# X = numpy.concatenate((X_train, X_test), axis=0)\n",
    "# y = numpy.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize word sentiment dataset or toxicity dataset (wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sentiment word dataset from positve/negative reviews\n",
    "#'''\n",
    "pos_words_fil = filter(lambda x:  x in embeddings,map(lambda x: x,pos_words))\n",
    "neg_words_fil = filter(lambda x:  x in embeddings,map(lambda x: x,neg_words))\n",
    "pos_vectors = embeddings[pos_words_fil]\n",
    "neg_vectors = embeddings[neg_words_fil]\n",
    "vectors = np.concatenate([pos_vectors, neg_vectors])\n",
    "targets = np.array([0 for entry in pos_vectors] + [1 for entry in neg_vectors])\n",
    "labels = list(pos_vectors) + list(neg_vectors)\n",
    "train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = train_test_split(vectors, targets, labels, test_size=0.1, random_state=0)\n",
    "#'''\n",
    "#toxicity tweet dataset\n",
    "#''''''\n",
    "# toxic_sentences = df[df[\"toxic\"]==1][\"comment_text\"]\n",
    "# num_toxic_samples = len(toxic_sentences)\n",
    "# non_toxic_sentences = df[df[\"toxic\"]==0][\"comment_text\"].sample(num_toxic_samples)\n",
    "# sentences = pd.concat([toxic_sentences, non_toxic_sentences])\n",
    "# targets  = np.zeros(num_toxic_samples*2)\n",
    "# targets[0:num_toxic_samples] = 1\n",
    "# train_vectors, test_vectors, train_targets, test_targets = generate_train_test_set(embeddings,targets,sentences)\n",
    "# sentences = map(lambda x: re.sub('[^A-Za-z0-9 ]+', '', x.lower()),list(sentences))\n",
    "# # message_embeddings = None\n",
    "# # with tf.Session() as session:\n",
    "# #     session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "# #     message_embeddings = session.run(embed(sentences))\n",
    "# #     print np.shape(message_embeddings)\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vec = TfidfVectorizer(ngram_range=(1,2),\n",
    "#                min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "#                smooth_idf=1, sublinear_tf=1)\n",
    "# trn_term_doc = vec.fit_transform(sentences)\n",
    "\n",
    "# train_vectors, test_vectors, train_targets, test_targets = train_test_split(trn_term_doc.todense(), targets,test_size=0.1, random_state=0)\n",
    "\n",
    "#'''\n",
    "\n",
    "\n",
    "    \n",
    "# import re, string\n",
    "# re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "# def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "# n = train.shape[0]\n",
    "# vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "#                min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "#                smooth_idf=1, sublinear_tf=1 )\n",
    "# trn_term_doc = vec.fit_transform(train[COMMENT])\n",
    "# test_term_doc = vec.transform(test[COMMENT])\n",
    "#imbd movie ratings?????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_component(matrix, row_index):\n",
    "    return np.delete(matrix,row_index,1)\n",
    "\n",
    "# Deprecated. Or at least not used right now.\n",
    "def remove_principle_component(X_matrix, component_index):\n",
    "    u, s, vt = np.linalg.svd(X_matrix, full_matrices=False)\n",
    "    u_new = np.delete(u, component_index, 1)    \n",
    "    s_new = np.delete(s, component_index) \n",
    "    vt_new = np.delete(vt, component_index, 0)\n",
    "    return np.mat(u_new)* np.diag(s_new) * np.mat(vt_new)\n",
    "\n",
    "# Deprecated. Or at least not used right now.\n",
    "def leave_one_out(X_matrix):\n",
    "    print(\"leaving one out...\")\n",
    "    list_of_Xs = []\n",
    "    for i in range(X_matrix.shape[1]):\n",
    "        X_without_i = remove_principle_component(X_matrix, i)\n",
    "        list_of_Xs.append(np.array(X_without_i))\n",
    "    return list_of_Xs\n",
    "\n",
    "def leave_one_out_efficiently(X_matrix, num_top_components_to_remove=float('inf')):\n",
    "    list_of_Xs = []\n",
    "    u, s, vt = np.linalg.svd(X_matrix, full_matrices=False)\n",
    "    \n",
    "    for i in range(min(X_matrix.shape[1], num_top_components_to_remove)):\n",
    "        u_new = np.delete(u, i, 1)    \n",
    "        s_new = np.delete(s, i) \n",
    "        vt_new = np.delete(vt, i, 0)\n",
    "        X_without_i = np.mat(u_new)* np.diag(s_new) * np.mat(vt_new)\n",
    "        list_of_Xs.append(np.array(X_without_i))\n",
    "    return list_of_Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_lr_on_this_data(new_train_vectors):    \n",
    "    lr = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[0,0,0],lamb=0.01,num_iter=8000)\n",
    "    (RNSB,loss,validation_scores) = lr.fit(new_train_vectors,train_targets)\n",
    "    return lr\n",
    "    print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_loo_experiment(num_singular_vectors):\n",
    "    leave_one_out_matricies = leave_one_out_efficiently(train_vectors, num_singular_vectors)\n",
    "\n",
    "#     Un-pca'd LR\n",
    "    og_lr = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[0,0,0],lamb=0.01,num_iter=4000)\n",
    "    (RNSB,loss,validation_scores) = og_lr.fit(train_vectors,train_targets)\n",
    "\n",
    "    lr_metrics = []\n",
    "    \n",
    "    for i in range(len(leave_one_out_matricies)):\n",
    "        lr_metrics.append(run_lr_on_this_data(leave_one_out_matricies[i]))\n",
    "        print(\"finished with \" + str(i) + \" runs of \" + str(len(leave_one_out_matricies)))\n",
    "        print(\"____________________\")\n",
    "        print()\n",
    "        \n",
    "    return lr_metrics#, og_lr \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need here for regularizers, even if all are zero.\n",
    "N = np.zeros((len(nationalities),300))\n",
    "for i,j in enumerate(nationalities):\n",
    "    N[i,:] = embeddings[j.lower()]\n",
    "R = np.zeros((len(religions),300))\n",
    "for i,j in enumerate(religions):\n",
    "    R[i,:] = embeddings[j.lower()]\n",
    "G = np.zeros((len(gender),300))\n",
    "for i,j in enumerate(gender):\n",
    "    G[i,:] = embeddings[j.lower()]\n",
    "regularizers = [N,R,G]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_metrics, og_lr = run_loo_experiment(20)\n",
    "    \n",
    "lr_metrics = run_loo_experiment(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.67731607316 0.0 0.0\n",
      "loss:  0.690806938888\n",
      "validation MAp:  0.774038461538\n",
      "RNSB:  [1.2337028740690939e-07, 2.1538976197832401e-06, 3.7378536644028877e-07]\n",
      "1.48099565479 0.447926492306 0.0\n",
      "loss:  0.314153624448\n",
      "validation MAp:  0.900641025641\n",
      "RNSB:  [0.042099657028117535, 0.070295260016458527, 0.024795884737000493]\n",
      "1.0262187447 0.580921375259 0.0\n",
      "loss:  0.270939466524\n",
      "validation MAp:  0.911858974359\n",
      "RNSB:  [0.070477078261294041, 0.096361227460164553, 0.040996409070636078]\n",
      "0.869473784181 0.64328313835 0.0\n",
      "loss:  0.255417367627\n",
      "validation MAp:  0.908653846154\n",
      "RNSB:  [0.084833309095563539, 0.10962604330265141, 0.049544524539065243]\n"
     ]
    }
   ],
   "source": [
    "og_lr = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[0,0,0],lamb=0.01,num_iter=4000)\n",
    "(RNSB,loss,validation_scores) = og_lr.fit(train_vectors,train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91025641025641024"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_lr.validation(og_lr.val[0],og_lr.val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_RNSB_bar(lr_list, og_lr):\n",
    "    \n",
    "    rnsb_list = [i.validation_fairness() for i in lr_list]\n",
    "    metric_a, metric_b, metric_c  = zip(*rnsb_list)\n",
    "    \n",
    "#     identity_toxicity = dict(identity_toxicity_table(nationalities,embeddings,lr))\n",
    "#     identity_toxicity = list(zip(*identity_toxicity.items()))\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(\"National Origin\",fontsize=20)\n",
    "    index = np.arange(len(metric_a)) + 1\n",
    "    plt.bar(index,metric_a)\n",
    "    plt.xticks(index, index, fontsize=15, rotation=45)\n",
    "    plt.axes().axhline(y=og_lr.validation_fairness()[0], color=\"gray\")\n",
    "    plt.ylabel(\"RNSB\",fontsize=16)\n",
    "    plt.xlabel(\"nth-largest singular vector removed\",fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(\"Religion\",fontsize=20)\n",
    "    index = np.arange(len(metric_b)) + 1\n",
    "    plt.bar(index,metric_b)\n",
    "    plt.xticks(index, index, fontsize=15, rotation=45)\n",
    "    plt.axes().axhline(y=og_lr.validation_fairness()[1], color=\"gray\")\n",
    "    plt.ylabel(\"RNSB\",fontsize=16)\n",
    "    plt.xlabel(\"nth-largest singular vector removed\",fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(\"Gender\",fontsize=20)\n",
    "    index = np.arange(len(metric_c)) + 1\n",
    "    plt.bar(index,metric_c)\n",
    "    plt.xticks(index, index, fontsize=15, rotation=45)\n",
    "    plt.axes().axhline(y=og_lr.validation_fairness()[2], color=\"gray\")\n",
    "    plt.ylabel(\"RNSB\",fontsize=16)\n",
    "    plt.xlabel(\"nth-largest singular vector removed\",fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "print(og_lr.validation_fairness())\n",
    "for lr in lr_metrics:\n",
    "    print(lr.validation(lr.val[0],lr.val[1]))\n",
    "plot_RNSB_bar(lr_metrics, og_lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_data(labels, points, plt):\n",
    "    \n",
    "    for label, point in zip(labels, points):\n",
    "        plt.annotate(label,xy=point,fontsize=15)\n",
    "    \n",
    "\n",
    "def plot_RNSB_scatter(lr_list, og_lr):\n",
    "    \n",
    "    rnsb_list = [lr.validation_fairness() for lr in lr_list]\n",
    "    validation_list = [lr.validation(lr.val[0],lr.val[1]) for lr in lr_list]\n",
    "    metric_a, metric_b, metric_c  = zip(*rnsb_list)\n",
    "    \n",
    "    og_rnsb_a, og_rnsb_b, og_rnsb_c = og_lr.validation_fairness()\n",
    "    og_validation = og_lr.validation(og_lr.val[0],og_lr.val[1])\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(\"National Origin\",fontsize=20)\n",
    "    plt.xlabel(\"Validation Accuracy\")\n",
    "    plt.ylabel(\"RNSB\")\n",
    "    plt.scatter(validation_list, metric_a)\n",
    "    plt.scatter(og_validation, og_rnsb_a, color=\"red\")\n",
    "    plt.axes().axhline(y=og_rnsb_a, color=\"gray\")\n",
    "    plt.axes().axvline(x=og_validation, color=\"gray\")\n",
    "    annotate_data([str(i+1) for i in range(len(lr_list))], zip(validation_list, metric_a), plt)\n",
    "    plt.show()\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(\"Religion\",fontsize=20)\n",
    "    plt.xlabel(\"Validation Accuracy\")\n",
    "    plt.ylabel(\"RNSB\")\n",
    "    plt.scatter(validation_list, metric_b)\n",
    "    plt.scatter(og_validation, og_rnsb_b, color=\"red\")\n",
    "    plt.axes().axhline(y=og_rnsb_b, color=\"gray\")\n",
    "    plt.axes().axvline(x=og_validation, color=\"gray\")\n",
    "    annotate_data([str(i+1) for i in range(len(lr_list))], zip(validation_list, metric_b), plt)\n",
    "    plt.show()\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(\"Gender\",fontsize=20)\n",
    "    plt.xlabel(\"Validation Accuracy\")\n",
    "    plt.ylabel(\"RNSB\")\n",
    "    plt.scatter(validation_list, metric_c)\n",
    "    plt.scatter(og_validation, og_rnsb_c, color=\"red\")\n",
    "    plt.axes().axhline(y=og_rnsb_c, color=\"gray\")\n",
    "    plt.axes().axvline(x=og_validation, color=\"gray\")\n",
    "    annotate_data([str(i+1) for i in range(len(lr_list))], zip(validation_list, metric_c), plt)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_RNSB_scatter(lr_metrics, og_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RNSB vs Accuracy for Reg and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.67731607316 0.0 0.0\n",
      "loss:  0.690806938888\n",
      "validation MAp:  0.774038461538\n",
      "RNSB:  [1.2337028740690939e-07, 2.1538976197832401e-06, 3.7378536644028877e-07]\n",
      "1.48099565479 0.447926492306 0.0\n",
      "loss:  0.314153624448\n",
      "validation MAp:  0.900641025641\n",
      "RNSB:  [0.042099657028117535, 0.070295260016458527, 0.024795884737000493]\n",
      "1.0262187447 0.580921375259 0.0\n",
      "loss:  0.270939466524\n",
      "validation MAp:  0.911858974359\n",
      "RNSB:  [0.070477078261294041, 0.096361227460164553, 0.040996409070636078]\n",
      "0.869473784181 0.64328313835 0.0\n",
      "loss:  0.255417367627\n",
      "validation MAp:  0.908653846154\n",
      "RNSB:  [0.084833309095563539, 0.10962604330265141, 0.049544524539065243]\n",
      "6.67731607316 0.0 260.230511771\n",
      "loss:  0.680765173817\n",
      "validation MAp:  0.559294871795\n",
      "RNSB:  [0.001136268238864693, 0.019059643529175774, 0.0069855950655610972]\n",
      "2.06924401028 0.635108924153 1.64959396997\n",
      "loss:  0.3607926851\n",
      "validation MAp:  0.841346153846\n",
      "RNSB:  [0.049511161519375221, 0.2007048659848033, 0.064820225578583565]\n",
      "1.56804604778 0.748051720244 1.38866791567\n",
      "loss:  0.31400766145\n",
      "validation MAp:  0.860576923077\n",
      "RNSB:  [0.034118563908034173, 0.15928696753101862, 0.042399278394365428]\n",
      "1.39258938929 0.805635087507 1.29964323185\n",
      "loss:  0.296833691486\n",
      "validation MAp:  0.865384615385\n",
      "RNSB:  [0.02818205853936637, 0.13948725152247121, 0.035253956851152707]\n"
     ]
    }
   ],
   "source": [
    "# Original, non-fairness whatever lr\n",
    "og_lr = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[0,0,0],lamb=0.01,num_iter=4000)\n",
    "(RNSB_debias,loss_debias,validation_scores_debias) = og_lr.fit(train_vectors,train_targets)\n",
    "\n",
    "# Regularized\n",
    "lr_debias = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[.2,.2,.2],lamb=0.01,num_iter=4000)\n",
    "(RNSB_debias,loss_debias,validation_scores_debias) = lr_debias.fit(train_vectors,train_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.56384235671 0.0 0.0\n",
      "loss:  0.690856537904\n",
      "validation MAp:  0.777243589744\n",
      "RNSB:  [9.4537982424941643e-08, 1.8962333443739011e-06, 3.2259507139171346e-07]\n",
      "1.48859468565 0.443235353959 0.0\n",
      "loss:  0.32675841767\n",
      "validation MAp:  0.900641025641\n",
      "RNSB:  [0.027611201890838225, 0.039258764326004114, 0.020620928552867519]\n",
      "1.03215893087 0.579222693007 0.0\n",
      "loss:  0.284219368225\n",
      "validation MAp:  0.918269230769\n",
      "RNSB:  [0.045636703431975165, 0.049776733846981808, 0.033045967005450469]\n",
      "0.872457725375 0.643380592881 0.0\n",
      "loss:  0.268799733933\n",
      "validation MAp:  0.919871794872\n",
      "RNSB:  [0.054751121615285461, 0.055183588965741596, 0.039263267744931926]\n",
      "6.56384235671 0.0 260.230511771\n",
      "loss:  0.685278737818\n",
      "validation MAp:  0.557692307692\n",
      "RNSB:  [0.0011350029807384188, 0.019006149481594847, 0.006969010687720309]\n",
      "2.03732960245 0.636875983 1.58893157742\n",
      "loss:  0.375498329602\n",
      "validation MAp:  0.842948717949\n",
      "RNSB:  [0.049786082083991018, 0.20245578574384562, 0.062657587881341556]\n",
      "1.51798595129 0.752262307317 1.30328232469\n",
      "loss:  0.326643928989\n",
      "validation MAp:  0.857371794872\n",
      "RNSB:  [0.035591586159172545, 0.16274544918367978, 0.040334374169501634]\n",
      "1.3351092648 0.812602557517 1.2056678109\n",
      "loss:  0.308505972342\n",
      "validation MAp:  0.863782051282\n",
      "RNSB:  [0.030105945260730141, 0.14444140865215405, 0.033620318177034106]\n",
      "1.25170606811 0.846330205168 1.16241288067\n",
      "loss:  0.299892384488\n",
      "validation MAp:  0.86858974359\n",
      "RNSB:  [0.027116980789290739, 0.13356819227546873, 0.031234772232881663]\n",
      "1.20919806289 0.865907421955 1.14002417448\n",
      "loss:  0.295318213504\n",
      "validation MAp:  0.870192307692\n",
      "RNSB:  [0.025359297522934504, 0.12624092221162078, 0.03020884872230261]\n",
      "1.18621301436 0.877824332257 1.12758768486\n",
      "loss:  0.292724565571\n",
      "validation MAp:  0.866987179487\n",
      "RNSB:  [0.024312685293621239, 0.12114052558794124, 0.029698365777121795]\n",
      "1.17329219115 0.885264394348 1.12028253197\n",
      "loss:  0.291187614751\n",
      "validation MAp:  0.865384615385\n",
      "RNSB:  [0.023687126374041662, 0.11753187839438478, 0.029416361218304328]\n",
      "6.56384235671 0.0 130.115255886\n",
      "loss:  0.687237603382\n",
      "validation MAp:  0.572115384615\n",
      "RNSB:  [0.00021763302495721171, 0.0039561294806250216, 0.0014186525091715403]\n",
      "1.96923858522 0.616946126512 1.4845673757\n",
      "loss:  0.369452962387\n",
      "validation MAp:  0.844551282051\n",
      "RNSB:  [0.084048716451581851, 0.26729695747831711, 0.098544562566017346]\n",
      "1.45168533959 0.734448507319 1.20930467424\n",
      "loss:  0.320868580519\n",
      "validation MAp:  0.862179487179\n",
      "RNSB:  [0.068581184369611636, 0.23555368077700239, 0.076785434773581032]\n",
      "1.27029537454 0.794157191583 1.11806544557\n",
      "loss:  0.302871697729\n",
      "validation MAp:  0.86858974359\n",
      "RNSB:  [0.060110629090146889, 0.22020564245292401, 0.066112139877448961]\n",
      "1.18751636927 0.827058210919 1.07583317061\n",
      "loss:  0.294319821423\n",
      "validation MAp:  0.878205128205\n",
      "RNSB:  [0.055383295660086138, 0.21112571405939012, 0.060741794848501375]\n",
      "1.14498618725 0.84612950129 1.05389383598\n",
      "loss:  0.28976148818\n",
      "validation MAp:  0.879807692308\n",
      "RNSB:  [0.052514384338847128, 0.2052278940326768, 0.057962634774962385]\n",
      "1.12174250384 0.857423961223 1.04145142722\n",
      "loss:  0.287168258604\n",
      "validation MAp:  0.878205128205\n",
      "RNSB:  [0.050676167437766761, 0.20113791318738469, 0.056459801515095276]\n",
      "1.108546575 0.864398008373 1.03402235913\n",
      "loss:  0.28562764655\n",
      "validation MAp:  0.878205128205\n",
      "RNSB:  [0.049465050123195867, 0.19819626130144352, 0.055612087305211465]\n"
     ]
    }
   ],
   "source": [
    "train_vectors_5 = np.array(remove_principle_component(train_vectors,4))\n",
    "\n",
    "# Removing 5th principle component\n",
    "lr_minus5 = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[0,0,0],lamb=0.01,num_iter=4000)\n",
    "(RNSB_debias,loss_debias,validation_scores_debias) = lr_minus5.fit(train_vectors_5, train_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.56384235671 0.0 390.345767657\n",
      "loss:  0.684959005004\n",
      "validation MAp:  0.55608974359\n",
      "RNSB:  [0.003158537783207651, 0.049705772998804229, 0.01893993835519394]\n",
      "2.08860047227 0.648061761839 1.67256987856\n",
      "loss:  0.379814066937\n",
      "validation MAp:  0.841346153846\n",
      "RNSB:  [0.031774617265509855, 0.15787686883230098, 0.040414580627086708]\n",
      "1.56628099633 0.764453639309 1.36838135515\n",
      "loss:  0.33082440947\n",
      "validation MAp:  0.855769230769\n",
      "RNSB:  [0.021589362596965825, 0.11557819013939802, 0.02437172982035643]\n",
      "1.38252219733 0.823815151847 1.27248919208\n",
      "loss:  0.312583779648\n",
      "validation MAp:  0.858974358974\n",
      "RNSB:  [0.01768626359246106, 0.096908607308082872, 0.021143412544296896]\n",
      "1.29913333747 0.857772452753 1.23077334056\n",
      "loss:  0.30392909809\n",
      "validation MAp:  0.860576923077\n",
      "RNSB:  [0.01583939203777926, 0.085592251449782733, 0.020123298396498908]\n",
      "1.25688470061 0.877660939888 1.20949072122\n",
      "loss:  0.29933748712\n",
      "validation MAp:  0.862179487179\n",
      "RNSB:  [0.014905803896708075, 0.078069991312477841, 0.01966656745583634]\n",
      "1.23377195804 0.890174271875 1.19745566031\n",
      "loss:  0.296742065582\n",
      "validation MAp:  0.858974358974\n",
      "RNSB:  [0.014403932513274162, 0.072817053189444814, 0.019413955596482402]\n",
      "1.22051503045 0.898226176222 1.19020003597\n",
      "loss:  0.295210825217\n",
      "validation MAp:  0.858974358974\n",
      "RNSB:  [0.014121319271145299, 0.069060828041437969, 0.019259979666485377]\n",
      "6.56384235671 0.0 520.461023542\n",
      "loss:  0.686244856907\n",
      "validation MAp:  0.55608974359\n",
      "RNSB:  [0.0066302044150326964, 0.098474347323437239, 0.039726186497464365]\n",
      "2.13071742939 0.65572147909 1.74117609481\n",
      "loss:  0.383362016291\n",
      "validation MAp:  0.839743589744\n",
      "RNSB:  [0.021885670693687714, 0.12342925964053023, 0.0269934447130687]\n",
      "1.60502433002 0.772954122585 1.42827701534\n",
      "loss:  0.334186208946\n",
      "validation MAp:  0.850961538462\n",
      "RNSB:  [0.014307443719668194, 0.08227175710089539, 0.016862043217415593]\n",
      "1.4201301981 0.832336155392 1.33180917161\n",
      "loss:  0.315821678492\n",
      "validation MAp:  0.854166666667\n",
      "RNSB:  [0.0116821547706991, 0.063994985454994407, 0.015239912374675608]\n",
      "1.33565271886 0.867011120525 1.28757950614\n",
      "loss:  0.307080254756\n",
      "validation MAp:  0.857371794872\n",
      "RNSB:  [0.010576789687096281, 0.053241118311037908, 0.014679952311568233]\n",
      "1.29151102057 0.887726926171 1.26260017197\n",
      "loss:  0.302402523752\n",
      "validation MAp:  0.857371794872\n",
      "RNSB:  [0.010002849591577117, 0.046663024259880163, 0.014358963684610196]\n",
      "1.26651980101 0.900587835782 1.24693205506\n",
      "loss:  0.299706826634\n",
      "validation MAp:  0.858974358974\n",
      "RNSB:  [0.0096677365651859724, 0.042735604878324673, 0.014134359680642215]\n",
      "1.25162592422 0.90883043158 1.23685208462\n",
      "loss:  0.29807182924\n",
      "validation MAp:  0.858974358974\n",
      "RNSB:  [0.0094626720465022449, 0.040453886594188006, 0.013969597993661056]\n"
     ]
    }
   ],
   "source": [
    "# Removing 5th principle component AND Regularized\n",
    "lr_minus5_reg = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[.3,.3,.3],lamb=0.01,num_iter=8000)\n",
    "(RNSB_debias,loss_debias,validation_scores_debias) = lr_minus5_reg.fit(train_vectors_5, train_targets)\n",
    "\n",
    "# Removing 5th principle component AND Regularized, with .1, .1, .1\n",
    "lr_minus5_reg2 = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[.4,.4,.4],lamb=0.01,num_iter=8000)\n",
    "(RNSB_debias,loss_debias,validation_scores_debias) = lr_minus5_reg2.fit(train_vectors_5, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(lr_):\n",
    "    a,b,c = lr_.validation_fairness()\n",
    "    acc = lr_.validation(lr_.val[0], lr_.val[1])\n",
    "    return ((a,b,c),acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0.059524832628512103, 0.058153100527626171, 0.042533280736115148), 0.91987179487179482)\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics(lr_minus5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni1WwBN6qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1467334a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x146045ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1460e86d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def annotate_data(labels, points, plt):\n",
    "\n",
    "    for label, point in zip(labels, points):\n",
    "        plt.annotate(label,xy=point,fontsize=15)\n",
    "    \n",
    "\n",
    "def plot_RNSB_scatter(og_lr, lr_debias, lr_minus5, lr_minus5_reg, lr_minus5_reg2):\n",
    "    \n",
    "#     rnsb_list = [lr.validation_fairness() for lr in lr_list]\n",
    "#     validation_list = [lr.validation(lr.val[0],lr.val[1]) for lr in lr_list]\n",
    "#     metric_a, metric_b, metric_c  = zip(*rnsb_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    (og_rnsb_a, og_rnsb_b, og_rnsb_c), og_acc = get_metrics(og_lr)\n",
    "    (debias_rnsb_a, debias_rnsb_b, debias_rnsb_c), debias_acc = get_metrics(lr_debias)\n",
    "    (minus5_rnsb_a, minus5_rnsb_b, minus5_rnsb_c), minus5_acc = get_metrics(lr_minus5)\n",
    "    (minus5_reg_rnsb_a, minus5_reg_rnsb_b, minus5_reg_rnsb_c), minus5_reg_acc = get_metrics(lr_minus5_reg)\n",
    "    (minus5_reg2_rnsb_a, minus5_reg2_rnsb_b, minus5_reg2_rnsb_c), minus5_reg2_acc = get_metrics(lr_minus5_reg2)\n",
    "\n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(\"National Origin\",fontsize=20)\n",
    "    plt.xlabel(\"Validation Accuracy\")\n",
    "    plt.ylabel(\"RNSB\")\n",
    "    plt.scatter(og_acc, og_rnsb_a, color=\"red\")\n",
    "    plt.scatter(debias_acc, debias_rnsb_a, color=\"green\")\n",
    "    plt.scatter(minus5_acc, minus5_rnsb_a, color=\"blue\")\n",
    "    plt.scatter(minus5_reg_acc, minus5_reg_rnsb_a, color=\"cyan\")\n",
    "    plt.scatter(minus5_reg2_acc, minus5_reg2_rnsb_a, color=\"magenta\")\n",
    "    plt.axes().axhline(y=og_rnsb_a, color=\"gray\")\n",
    "    plt.axes().axvline(x=og_acc, color=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(\"National Origin\",fontsize=20)\n",
    "    plt.xlabel(\"Validation Accuracy\")\n",
    "    plt.ylabel(\"RNSB\")\n",
    "    plt.scatter(og_acc, og_rnsb_b, color=\"red\")\n",
    "    plt.scatter(debias_acc, debias_rnsb_b, color=\"green\")\n",
    "    plt.scatter(minus5_acc, minus5_rnsb_b, color=\"blue\")\n",
    "    plt.scatter(minus5_reg_acc, minus5_reg_rnsb_b, color=\"cyan\")\n",
    "    plt.scatter(minus5_reg2_acc, minus5_reg2_rnsb_b, color=\"magenta\")\n",
    "    plt.axes().axhline(y=og_rnsb_b, color=\"gray\")\n",
    "    plt.axes().axvline(x=og_acc, color=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(\"National Origin\",fontsize=20)\n",
    "    plt.xlabel(\"Validation Accuracy\")\n",
    "    plt.ylabel(\"RNSB\")\n",
    "    plt.scatter(og_acc, og_rnsb_c, color=\"red\")\n",
    "    plt.scatter(debias_acc, debias_rnsb_c, color=\"green\")\n",
    "    plt.scatter(minus5_acc, minus5_rnsb_c, color=\"blue\")\n",
    "    plt.scatter(minus5_reg_acc, minus5_reg_rnsb_c, color=\"cyan\")\n",
    "    plt.scatter(minus5_reg2_acc, minus5_reg2_rnsb_c, color=\"magenta\")\n",
    "    plt.axes().axhline(y=og_rnsb_c, color=\"gray\")\n",
    "    plt.axes().axvline(x=og_acc, color=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "plot_RNSB_scatter(og_lr, lr_debias, lr_minus5, lr_minus5_reg, lr_minus5_reg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fair regression terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = np.zeros((len(nationalities),300))\n",
    "for i,j in enumerate(nationalities):\n",
    "    N[i,:] = embeddings[j.lower()]\n",
    "R = np.zeros((len(religions),300))\n",
    "for i,j in enumerate(religions):\n",
    "    R[i,:] = embeddings[j.lower()]\n",
    "G = np.zeros((len(gender),300))\n",
    "for i,j in enumerate(gender):\n",
    "    G[i,:] = embeddings[j.lower()]\n",
    "regularizers = [N,R,G]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(20):\n",
    "#     # Create new train/test split, because using \"new\" training data each time\n",
    "#     print(\"removing pca component: \" + str(i))\n",
    "#     train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \\\n",
    "#         train_test_split(vectors, targets, labels, test_size=0.1, random_state=0)\n",
    "        \n",
    "#     lr = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[0,0,0],lamb=0.01,num_iter=8000)\n",
    "#     (RNSB,loss,validation_scores) = lr.fit(train_vectors,train_targets)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[0,0,0],lamb=0.01,num_iter=8000)\n",
    "(RNSB,loss,validation_scores) = lr.fit(train_vectors,train_targets)\n",
    "print(\"----------------------------------------------\")\n",
    "lr_debias = LogisticRegression(val=(test_vectors,test_targets),X_tils = regularizers,reg_coeff=[.2,.2,.2],lamb=0.01,num_iter=8000)\n",
    "(RNSB_debias,loss_debias,validation_scores_debias) = lr_debias.fit(train_vectors,train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot toxicity histogram for identity terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_debias.validation_fairness(),lr.validation_fairness()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity_toxicity = dict(identity_toxicity_table(gender,embeddings,lr))\n",
    "identity_toxicity = zip(*identity_toxicity.items())\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.title(\"Toxicity Classification Distribution\",fontsize=20)\n",
    "index = np.arange(len(identity_toxicity[0]))\n",
    "plt.bar(index,identity_toxicity[1]/np.sum(identity_toxicity[1]))\n",
    "plt.xticks(index, identity_toxicity[0], fontsize=15, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms= []\n",
    "for i in nationalities:\n",
    "    terms.append(\"i love \" + i + \" food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity_toxicity = dict(identity_toxicity_table(terms,embeddings,lr))\n",
    "identity_toxicity = zip(*identity_toxicity.items())\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.title(\"Toxicity Classification Distribution\",fontsize=20)\n",
    "index = np.arange(len(identity_toxicity[0]))\n",
    "plt.bar(index,identity_toxicity[1]/np.sum(identity_toxicity[1]))\n",
    "plt.xticks(index, identity_toxicity[0], fontsize=15, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity_toxicity = dict(identity_toxicity_table(terms,embeddings,lr_debias))\n",
    "identity_toxicity = zip(*identity_toxicity.items())\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.title(\"Toxicity Classification Distribution\",fontsize=20)\n",
    "index = np.arange(len(identity_toxicity[0]))\n",
    "plt.bar(index,identity_toxicity[1]/np.sum(identity_toxicity[1]))\n",
    "plt.xticks(index, identity_toxicity[0], fontsize=15, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity_toxicity = dict(identity_toxicity_table(gender,embeddings,lr_debias))\n",
    "identity_toxicity = zip(*identity_toxicity.items())\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.title(\"Toxicity Classification Distribution\",fontsize=20)\n",
    "index = np.arange(len(identity_toxicity[0]))\n",
    "plt.bar(index,identity_toxicity[1]/np.sum(identity_toxicity[1]))\n",
    "plt.xticks(index, identity_toxicity[0], fontsize=15, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(zip(*RNSB)[0],label=\"National Identity\")\n",
    "plt.plot(zip(*RNSB)[1],label=\"Religion\")\n",
    "plt.plot(zip(*RNSB)[2],label=\"Gender\")\n",
    "\n",
    "#maybe also do analysi with no regulaization\n",
    "\n",
    "\n",
    "plt.title(\"Sentence Toxicity Classifcation, No Fair Regularization\")\n",
    "plt.xlabel(\"training steps\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(zip(*RNSB_debias)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(zip(*RNSB_debias)[0][np.argmax(zip(*RNSB_debias)[0]):],label=\"National Identity\")\n",
    "plt.plot(zip(*RNSB_debias)[1][np.argmax(zip(*RNSB_debias)[1]):],label=\"Religion\")\n",
    "plt.plot(zip(*RNSB_debias)[2][np.argmax(zip(*RNSB_debias)[2]):],label=\"Gender\")\n",
    "\n",
    "\n",
    "plt.title(\"Sentence Toxicity Classifcation\")\n",
    "plt.xlabel(\"training steps\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test toxicity on gender equalized vs non equalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr,embeddings,'fuck'),text_to_toxicity(lr_debias,embeddings,'fuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr,embeddings,'US'),text_to_toxicity(lr,embeddings,'mexico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr_debias,embeddings,'US'),text_to_toxicity(lr_debias,embeddings,'mexico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr,embeddings,'i am american'),text_to_toxicity(lr,embeddings,'i am mexican')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr_debias,embeddings,'i am american'),text_to_toxicity(lr_debias,embeddings,\"i am mexican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr,embeddings,'catholic'),text_to_toxicity(lr,embeddings,'jewish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr_debias,embeddings,'catholic'),text_to_toxicity(lr_debias,embeddings,'jewish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr,embeddings,'male'),text_to_toxicity(lr,embeddings,'female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr_debias,embeddings,'male'),text_to_toxicity(lr_debias,embeddings,'female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr,embeddings,'boy'),text_to_toxicity(lr,embeddings,'girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr_debias,embeddings,'boy'),text_to_toxicity(lr_debias,embeddings,'girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_toxicity(lr_debias,embeddings,'dude'),text_to_toxicity(lr_debias,embeddings,'gal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create identity keyword toxicity histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity_toxicity_debias = dict(identity_toxicity_table(identities, embeddings_debiased,model_debias,add='/c/en/'))\n",
    "identity_toxicity = dict(identity_toxicity_table(identities,embeddings,model))\n",
    "keys_common = set(map(lambda x : x[6:] , identity_toxicity_debias.keys())).intersection(set(identity_toxicity.keys()))\n",
    "identity_toxicity_debias = {key: identity_toxicity_debias['/c/en/'+key] for key in keys_common }\n",
    "identity_toxicity = {key: identity_toxicity[key] for key in keys_common }\n",
    "identity_toxicity_debias = zip(*identity_toxicity_debias.items())\n",
    "identity_toxicity = zip(*identity_toxicity.items())\n",
    "%matplotlib inline\n",
    "f = plt.figure(figsize=(27, 18), dpi= 80, facecolor='w', edgecolor='k')\n",
    "f.subplots_adjust(hspace=.8)\n",
    "f.add_subplot(411)\n",
    "plt.title(\"Toxicity Classification Distribution\",fontsize=20)\n",
    "index = np.arange(len(identity_toxicity[0]))\n",
    "plt.bar(index,identity_toxicity[1]/np.sum(identity_toxicity[1]))\n",
    "plt.xticks(index, identity_toxicity[0], fontsize=15, rotation=45)\n",
    "plt.ylim(top=.06,bottom=0)\n",
    "f.add_subplot(412)\n",
    "plt.title(\"Concept Net Debiased Toxicity Classification Distribution\",fontsize=20)\n",
    "index = np.arange(len(identity_toxicity_debias[0]))\n",
    "plt.bar(index,identity_toxicity_debias[1]/np.sum(identity_toxicity_debias[1]))\n",
    "plt.xticks(index, identity_toxicity_debias[0], fontsize=15, rotation=45)\n",
    "plt.ylim(top=.06,bottom=0)\n",
    "f.add_subplot(413)\n",
    "plt.title(\"Delta\",fontsize=20)\n",
    "index = np.arange(len(identity_toxicity_debias[0]))\n",
    "delta = identity_toxicity[1]/np.sum(identity_toxicity[1])-identity_toxicity_debias[1]/np.sum(identity_toxicity_debias[1])\n",
    "bar = plt.bar(index,delta)\n",
    "for i,j in enumerate(delta):\n",
    "    bar[i].set_color('r') if j<0 else bar[i].set_color('g')\n",
    "plt.xticks(index, identity_toxicity_debias[0], fontsize=15, rotation=45)\n",
    "plt.ylim(top=.06,bottom=-.06)\n",
    "f.add_subplot(414)\n",
    "plt.title('\"Fair\" Taget Distribution',fontsize=20)\n",
    "index = np.arange(len(identity_toxicity[0]))\n",
    "plt.bar(index,1./len(identity_toxicity[1]))\n",
    "plt.xticks(index, identity_toxicity[0], fontsize=15, rotation=45)\n",
    "plt.ylim(top=.06,bottom=0)\n",
    "plt.show()\n",
    "uniform_dist = np.ones(len(identity_toxicity[1]))*1./len(identity_toxicity[1])\n",
    "uniform_dist_d = np.ones(len(identity_toxicity_debias[1]))*1./len(identity_toxicity_debias[1])\n",
    "\n",
    "debiased_normalized = identity_toxicity_debias[1]/np.sum(identity_toxicity_debias[1])\n",
    "biased_normalized = identity_toxicity[1]/np.sum(identity_toxicity[1])\n",
    "kl_debiased = (debiased_normalized * np.log(debiased_normalized/uniform_dist_d)).sum()\n",
    "kl_biased = (biased_normalized * np.log(biased_normalized/uniform_dist)).sum()\n",
    "print 'kl divergence from uniform dist for concept net:',kl_debiased\n",
    "print 'kl divergence from uniform dist for google news:',kl_biased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model comparison with different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "identity_toxicity_debias = dict(identity_toxicity_table(nationalities, embeddings,model_debias_kernel))\n",
    "identity_toxicity = dict(identity_toxicity_table(nationalities,embeddings,model))\n",
    "# keys_common = set(map(lambda x : x[6:] , identity_toxicity_debias.keys())).intersection(set(identity_toxicity.keys()))\n",
    "# identity_toxicity_debias = {key: identity_toxicity_debias[key] for key in keys_common }\n",
    "# identity_toxicity = {key: identity_toxicity[key] for key in keys_common }\n",
    "identity_toxicity_debias = zip(*identity_toxicity_debias.items())\n",
    "identity_toxicity = zip(*identity_toxicity.items())\n",
    "%matplotlib inline\n",
    "f = plt.figure(figsize=(27, 18), dpi= 80, facecolor='w', edgecolor='k')\n",
    "f.subplots_adjust(hspace=1.2)\n",
    "f.add_subplot(411)\n",
    "plt.title(\"GloVe Negative Sentiment Distribution\",fontsize=35)\n",
    "index = np.arange(len(identity_toxicity[0]))\n",
    "plt.bar(index,identity_toxicity[1]/np.sum(identity_toxicity[1]))\n",
    "plt.xticks(index, identity_toxicity[0], fontsize=25, rotation=35)\n",
    "plt.ylim(top=.2,bottom=0)\n",
    "f.add_subplot(412)\n",
    "plt.title(\"GloVe Kernel Negative Sentiment Distribution\",fontsize=35)\n",
    "index = np.arange(len(identity_toxicity_debias[0]))\n",
    "plt.bar(index,identity_toxicity_debias[1]/np.sum(identity_toxicity_debias[1]))\n",
    "plt.xticks(index, identity_toxicity_debias[0], fontsize=25, rotation=35)\n",
    "plt.ylim(top=.2,bottom=0)\n",
    "f.add_subplot(413)\n",
    "plt.title(\"Delta Between Word Embedding Distributions\",fontsize=35)\n",
    "index = np.arange(len(identity_toxicity_debias[0]))\n",
    "delta = identity_toxicity[1]/np.sum(identity_toxicity[1])-identity_toxicity_debias[1]/np.sum(identity_toxicity_debias[1])\n",
    "bar = plt.bar(index,delta)\n",
    "for i,j in enumerate(delta):\n",
    "    bar[i].set_color('r') if j<0 else bar[i].set_color('g')\n",
    "plt.xticks(index, identity_toxicity_debias[0], fontsize=25, rotation=35)\n",
    "plt.ylim(top=.2,bottom=-.06)\n",
    "f.add_subplot(414)\n",
    "plt.title('Fair Uniform Taget Distribution',fontsize=35)\n",
    "index = np.arange(len(identity_toxicity[0]))\n",
    "plt.bar(index,1./len(identity_toxicity[1]))\n",
    "plt.xticks(index, identity_toxicity[0], fontsize=25, rotation=35)\n",
    "plt.ylim(top=.2,bottom=0)\n",
    "plt.show()\n",
    "uniform_dist = np.ones(len(identity_toxicity[1]))*1./len(identity_toxicity[1])\n",
    "uniform_dist_d = np.ones(len(identity_toxicity_debias[1]))*1./len(identity_toxicity_debias[1])\n",
    "\n",
    "debiased_normalized = identity_toxicity_debias[1]/np.sum(identity_toxicity_debias[1])\n",
    "biased_normalized = identity_toxicity[1]/np.sum(identity_toxicity[1])\n",
    "kl_debiased = (debiased_normalized * np.log(debiased_normalized/uniform_dist_d)).sum()\n",
    "kl_biased = (biased_normalized * np.log(biased_normalized/uniform_dist)).sum()\n",
    "print 'kl divergence from uniform dist for concept net:',kl_debiased\n",
    "print 'kl divergence from uniform dist for google news:',kl_biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.3)\n",
    "%matplotlib inline\n",
    "A = np.outer(identity_toxicity[1],identity_toxicity[1])\n",
    "\n",
    "df = DataFrame(A, index=identity_toxicity[0], columns=identity_toxicity[0])\n",
    "\n",
    "sns.heatmap(df, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.outer(identity_toxicity_debias[1],identity_toxicity_debias[1])\n",
    "\n",
    "df = DataFrame(A, index=identity_toxicity_debias[0], columns=identity_toxicity_debias[0])\n",
    "\n",
    "sns.heatmap(df, annot=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
